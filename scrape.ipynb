{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c2d4d6-f75e-4c81-9c0f-b80f08a26a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import TooManyRedirects\n",
    "import re\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2004d80-927a-4a9d-80e4-6e96fe9584f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic_page_init(movie_name):\n",
    "    movie_name = re.sub(r\"[^a-zA-Z]{1,}\", \"_\", movie_name).lower()\n",
    "    if movie_name[-1] == '_':\n",
    "        movie_name = movie_name[:-1]\n",
    "    print(f'Try to get response from https://www.rottentomatoes.com/m/{movie_name}/reviews')\n",
    "    response = requests.get(f'https://www.rottentomatoes.com/m/{movie_name}/reviews')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    critics = soup.find_all('div',class_ = 'review-row')\n",
    "\n",
    "    # find movie id\n",
    "    rtid = soup.find('script',{\"id\":\"mps-page-integration\"}).contents[0].replace('|','').strip()\n",
    "    rtid = [x for x in rtid.split(',') if 'rtid' in x][0].strip().split(':')[-1][1:-1]\n",
    "\n",
    "    load_btn = soup.find_all('rt-button',{'data-loadmoremanager':\"btnLoadMore:click\"})\n",
    "    if load_btn:\n",
    "        hasNextPage = True\n",
    "    else:\n",
    "        hasNextPage = False\n",
    "    return critics,rtid, hasNextPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9908e8-9902-4a40-aa26-f9e763eba9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic_page_follow(movie_id,start_token = None):\n",
    "    url = f'https://www.rottentomatoes.com/napi/movie/{movie_id}/reviews/all?after={start_token}%3D%3D&pageCount=20'\n",
    "    print(f'Using url:{url}')\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print('Aborted as response code is not 200')\n",
    "            return None\n",
    "    except error as e:\n",
    "        print(f'[request {url} failed] : {e}')\n",
    "    return json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea188e0e-5e9a-4fda-8003-f01c040ed7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_data_soup(critics):\n",
    "    critics_reviewer = critics.find_all('div',class_ = 'reviewer-name-and-publication')\n",
    "    disp_name = critics_reviewer[0].find( class_ = \"display-name\").contents[0].strip()\n",
    "    # find review_date\n",
    "    critics_score_content = [x for x in critics.find('p',class_ = 'original-score-and-url').contents if hasattr(x,'contents')]\n",
    "    def try_dt_map(x):\n",
    "        try:\n",
    "            dt = datetime.strptime(x.contents[0], '%b %d, %Y')\n",
    "            return dt\n",
    "        except:\n",
    "            return None\n",
    "    review_date = [dt for dt in list(map(try_dt_map,critics_score_content)) if bool(dt)]\n",
    "    if review_date:\n",
    "        review_date = review_date[0]\n",
    "    else:\n",
    "        review_date = 'Not found'\n",
    "        \n",
    "    # find score\n",
    "    critics_score_str = [x for x in critics.find('p',class_ = 'original-score-and-url').contents if not hasattr(x,'contents')]\n",
    "    def try_score_map(x):\n",
    "        try:\n",
    "            score = x.replace('|','').strip()\n",
    "            return score\n",
    "        except:\n",
    "            return None\n",
    "    review_score = [score for score in list(map(try_score_map,critics_score_str)) if bool(score)]\n",
    "    if review_score:\n",
    "        review_score = review_score[0].split()[-1].strip()\n",
    "    else:\n",
    "        review_score = 'Not found'\n",
    "\n",
    "    # find sentiment\n",
    "    review_sentiment = critics.find('score-icon-critics').attrs['sentiment']\n",
    "    # find review text\n",
    "    review_text = critics.find('p', class_ = 'review-text').contents[0]\n",
    "    if review_text:\n",
    "        review_text = review_text\n",
    "    else:\n",
    "        review_text = 'Not Found'\n",
    "        \n",
    "    return [disp_name,review_date,review_score,review_sentiment,review_text,1]\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea2600e3-113b-4a88-a085-d5731b8a1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_data_json(json_rvw_data, page = None):\n",
    "    def get_json_info(jsn,key):\n",
    "        if key in jsn.keys():\n",
    "            return jsn[key]\n",
    "        else:\n",
    "            return None\n",
    "    disp_name = get_json_info(json_rvw_data,'criticName')\n",
    "    review_date = get_json_info(json_rvw_data, 'creationDate')\n",
    "    review_date = datetime.strptime(json_rvw_data['creationDate'], '%b %d, %Y')\n",
    "    review_score = get_json_info(json_rvw_data, 'originalScore')\n",
    "    review_sentiment = get_json_info(json_rvw_data, 'scoreSentiment')\n",
    "    review_text = get_json_info(json_rvw_data, 'quote')\n",
    "\n",
    "    return [disp_name,review_date,review_score,review_sentiment,review_text,page]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b835edf-5c6f-46f5-bad7-2d28f625d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_reviews(movie_title):\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame({'movie_title':[],\n",
    "                       'movie_id':[],\n",
    "                       'reviewer_name':[],\n",
    "                       'review_date':[],\n",
    "                       'review_score':[],\n",
    "                       'review_sentiment':[],\n",
    "                       'review_text':[],\n",
    "                       'on_page':[]\n",
    "                        })\n",
    "    def append_review_df(df, movie_title, movie_id, reviewer_name, review_date, review_score, review_sentiment, review_text, on_page):\n",
    "        df_to_append = pd.DataFrame({'movie_title':[movie_title],\n",
    "                                     'movie_id':[movie_id],\n",
    "                                     'reviewer_name':[reviewer_name],\n",
    "                                     'review_date':[review_date],\n",
    "                                     'review_score':[review_score],\n",
    "                                     'review_sentiment':[review_sentiment],\n",
    "                                     'review_text':[review_text],\n",
    "                                     'on_page':[on_page]\n",
    "                                    })\n",
    "        return df._append(df_to_append, ignore_index = True)\n",
    "    # page1 init\n",
    "    init_pg_critics, rtid, hasNextPage = get_critic_page_init(movie_title)\n",
    "    # ingest page1 data\n",
    "    print(f'Scraping page{1} of {movie_title}')\n",
    "    for row in range(len(init_pg_critics)):\n",
    "        review_row = init_pg_critics[row]\n",
    "        rtid = get_critic_page_init(movie_title)[1]\n",
    "        review_row_data = get_review_data_soup(review_row)\n",
    "        df = append_review_df(df, movie_title, rtid, *review_row_data)\n",
    "    # end if no load more btn found\n",
    "    if not hasNextPage:\n",
    "        return df\n",
    "    \n",
    "    # other page\n",
    "    is_first_loop = True\n",
    "    while True:   \n",
    "        if is_first_loop:\n",
    "            start_token = 'MQ'\n",
    "        res = get_critic_page_follow(movie_id = rtid,start_token = start_token)\n",
    "        if not res: # the movie has no more review page\n",
    "            break\n",
    "        pg = 2 # page count\n",
    "        print(f'Scraping page{pg} of {movie_title} using start key = {start_token}')\n",
    "        for row in res['reviews']:\n",
    "            review_row_data = get_review_data_json(row, page = pg)\n",
    "            df = append_review_df(df, movie_title, rtid, *review_row_data)\n",
    "        is_first_loop = False # Disable init var\n",
    "        # check if has next page\n",
    "        print(res['pageInfo']['hasNextPage'])\n",
    "        if not res['pageInfo']['hasNextPage']:\n",
    "            return df      \n",
    "        start_token = res['pageInfo']['endCursor'].replace('==','')\n",
    "        print(f'Found next page token {start_token}')    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa44c958-476b-4658-994a-263038e17f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to get response from https://www.rottentomatoes.com/m/venom_the_last_dance/reviews\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m get_movie_reviews(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVenom: The Last Dance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m x\n",
      "Cell \u001b[1;32mIn[12], line 24\u001b[0m, in \u001b[0;36mget_movie_reviews\u001b[1;34m(movie_title)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39m_append(df_to_append, ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# page1 init\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m init_pg_critics, rtid, hasNextPage \u001b[38;5;241m=\u001b[39m get_critic_page_init(movie_title)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# ingest page1 data\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScraping page\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmovie_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36mget_critic_page_init\u001b[1;34m(movie_name)\u001b[0m\n\u001b[0;32m      8\u001b[0m critics \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m,class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview-row\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# find movie id\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m rtid \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscript\u001b[39m\u001b[38;5;124m'\u001b[39m,{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps-page-integration\u001b[39m\u001b[38;5;124m\"\u001b[39m})\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     12\u001b[0m rtid \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m rtid\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrtid\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     14\u001b[0m load_btn \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrt-button\u001b[39m\u001b[38;5;124m'\u001b[39m,{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata-loadmoremanager\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbtnLoadMore:click\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "x = get_movie_reviews('Venom: The Last Dance')\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13e2121b-4cff-4c34-86f9-0e7090509709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to get response from https://www.rottentomatoes.com/m/the_ring/reviews\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m get_movie_reviews(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe_ring\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m x\n",
      "Cell \u001b[1;32mIn[12], line 24\u001b[0m, in \u001b[0;36mget_movie_reviews\u001b[1;34m(movie_title)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39m_append(df_to_append, ignore_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# page1 init\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m init_pg_critics, rtid, hasNextPage \u001b[38;5;241m=\u001b[39m get_critic_page_init(movie_title)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# ingest page1 data\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScraping page\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmovie_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36mget_critic_page_init\u001b[1;34m(movie_name)\u001b[0m\n\u001b[0;32m      8\u001b[0m critics \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m,class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview-row\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# find movie id\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m rtid \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscript\u001b[39m\u001b[38;5;124m'\u001b[39m,{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps-page-integration\u001b[39m\u001b[38;5;124m\"\u001b[39m})\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     12\u001b[0m rtid \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m rtid\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrtid\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     14\u001b[0m load_btn \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrt-button\u001b[39m\u001b[38;5;124m'\u001b[39m,{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata-loadmoremanager\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbtnLoadMore:click\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "x = get_movie_reviews('the_ring')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a37fc4-7566-4897-b838-caa32070ad40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
